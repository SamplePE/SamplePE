<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="On optimal spatial sampling for learning SDF with positional encoding"
    />
    <meta name="keywords" content="Reinforcement Learning, Diffusion Model, Trajectory Optimization" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
        On optimal spatial sampling for learning SDF with positional encoding.
    </title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap"
      rel="stylesheet"
    />
    <link href="./public/index.css" rel="stylesheet" />
    <link href="./public/media.css" rel="stylesheet" />
    <link href="./public/sidebars.css" rel="stylesheet" />
    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="./public/js/base.js"></script>
  </head>

  <body>
    <div class="sidebarsWrapper">
      <div class="sidebars">
        <a class="barWrapper" clear href="#abstract-a" id="bar2"
          ><span>Abstract</span>
          <div class="bar"></div
        ></a>
        <a class="barWrapper" clear href="#tr2-a" id="bar3"
          ><span>Framework of SamplePE</span>
          <div class="bar"></div
        ></a>
        <a class="barWrapper" clear href="#results-a" id="bar4"
          ><span>Results</span>
          <div class="bar"></div
        ></a>
<!--        <a class="barWrapper" clear href="#attn-a" id="bar5"-->
<!--          ><span>Attention Analysis</span>-->
<!--          <div class="bar"></div-->
<!--        ></a>-->
      </div>
    </div>
    <main class="content">
      <section class="heading" style="text-align: center!important;">
        <h1 class="title">
          On Optimal Sampling for Learning SDF Using MLPs Equipped with Positional Encoding
        </h1>
        <section class="authors"  >
          <ul>
            <li>
              <span><a href="https://carrie-lin.github.io/">Guying Lin*</a><sup>1</sup></span>
            </li>
            <li>
              <span
                ><a href="https://scholar.google.com.hk/citations?user=JAzFhXQAAAAJ">Lei Yang*</a
                ><sup>1</sup></span>
            </li>

            <li>
              <span><a href="https://liuyuan-pal.github.io/">Yuan Liu</a>
                <sup>1</sup>
              </span>
            </li>

            <li>
              <span><a href="https://cong-yi.github.io/">Congyi Zhang</a>
                <sup>2</sup>
              </span>
            </li>

            <li>
              <span><a href="https://www.cityu.edu.hk/stfprofile/csjhhou.htm">Junhui Hou</a>
                <sup>3</sup>
              </span>
            </li>

            <li>
              <span><a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin</a>
                <sup>4</sup>
              </span>
            </li>

            <li>
              <span><a href="https://i.cs.hku.hk/~taku/">Taku Komura</a>
                <sup>1</sup>
              </span>
            </li>

            <li>
              <span><a href="https://people.engr.tamu.edu/keyser/index.html">John Keyser</a>
                <sup>5</sup>
              </span>
            </li>

            <li>
              <span><a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a>
                <sup>5</sup>
              </span>
            </li>

        (*: equal contribution)


          </ul>
        </section>
        <section class="affiliations">
          <ul>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>1</sup>The University of Hong Kong,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>2</sup>The University of British Columbia,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>3</sup>The City University of Hong Kong,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>4</sup>Zhejiang University,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>5</sup>Texas A&M University</li>
          </ul>
        </section>
        <section class="links">
          <ul>
            <a href="https://arxiv.org/pdf/2401.01391.pdf" rel="noreferrer" target="_blank">
              <li>
                <span class="icon"> <img src="./public/paper.svg" /> </span
                ><span>Paper</span>
              </li>
            </a>
          </ul>
        </section>
        <a class="anchor" id="abstract-a"></a>
        <h2>Abstract</h2>
        <p class="abstract" style="font-family: 'Times New Roman', Arial; text-align: justify">
 
          Neural implicit fields, such as the neural signed distance field (SDF) of a shape, have emerged as a powerful representation for many applications, e.g., encoding a 3D shape and performing collision detection. Typically, implicit fields are encoded by Multi-layer Perceptrons (MLP) with positional encoding (PE) to capture high-frequency geometric details. However, a notable side effect of such PE-equipped MLPs is the noisy artifacts present in the learned implicit fields. While increasing the sampling rate could in general mitigate these artifacts, in this paper we aim to explain this adverse phenomenon through the lens of Fourier analysis. We devise a tool to determine the appropriate sampling rate for learning an accurate neural implicit field without undesirable side effects. Specifically, we propose a simple yet effective method to estimate the intrinsic frequency of a given network with randomized weights based on the Fourier analysis of the network's responses. It is observed that a PE-equipped MLP has an intrinsic frequency much higher than the highest frequency component in the PE layer. Sampling against this intrinsic frequency following the Nyquist-Sannon sampling theorem allows us to determine an appropriate training sampling rate. We empirically show in the setting of SDF fitting that this recommended sampling rate is sufficient to secure accurate fitting results, while further increasing the sampling rate would not further noticeably reduce the fitting error. Training PE-equipped MLPs simply with our sampling strategy leads to performances superior to the existing methods.
      
  </p>
  <img style="position:relative;top: 15px;" src='public/images/teaser1.png' width="900">

      </section>


      <br />

    </main>
  </body>
</html>
