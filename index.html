<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="On optimal spatial sampling for learning SDF with positional encoding"
    />
    <meta name="keywords" content="Reinforcement Learning, Diffusion Model, Trajectory Optimization" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
        On optimal spatial sampling for learning SDF with positional encoding.
    </title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap"
      rel="stylesheet"
    />
    <link href="./public/index.css" rel="stylesheet" />
    <link href="./public/media.css" rel="stylesheet" />
    <link href="./public/sidebars.css" rel="stylesheet" />
    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="./public/js/base.js"></script>
  </head>

  <body>
    <div class="sidebarsWrapper">
      <div class="sidebars">
        <a class="barWrapper" clear href="#abstract-a" id="bar2"
          ><span>Abstract</span>
          <div class="bar"></div
        ></a>
        <a class="barWrapper" clear href="#tr2-a" id="bar3"
          ><span>Framework of SamplePE</span>
          <div class="bar"></div
        ></a>
        <a class="barWrapper" clear href="#results-a" id="bar4"
          ><span>Results</span>
          <div class="bar"></div
        ></a>
<!--        <a class="barWrapper" clear href="#attn-a" id="bar5"-->
<!--          ><span>Attention Analysis</span>-->
<!--          <div class="bar"></div-->
<!--        ></a>-->
      </div>
    </div>
    <main class="content">
      <section class="heading" style="text-align: center!important;">
        <h1 class="title">
            On  Optimal Spatial Sampling for Learning SDF with Positional Encoding
        </h1>
        <section class="authors"  >
          <ul>
            <li>
              <span><a href="https://carrie-lin.github.io/">Guying Lin</a><sup>1</sup></span>
            </li>
            <li>
              <span
                ><a href="https://scholar.google.com.hk/citations?user=JAzFhXQAAAAJ">Lei Yang</a
                ><sup>1</sup></span>
            </li>

            <li>
              <span><a href="https://liuyuan-pal.github.io/">Yuan Liu</a>
                <sup>1</sup>
              </span>
            </li>

            <li>
              <span><a href="https://cong-yi.github.io/">Congyi Zhang</a>
                <sup>2</sup>
              </span>
            </li>

            <li>
              <span><a href="https://www.cityu.edu.hk/stfprofile/csjhhou.htm">Junhui Hou</a>
                <sup>3</sup>
              </span>
            </li>

            <li>
              <span><a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin</a>
                <sup>4</sup>
              </span>
            </li>

            <li>
              <span><a href="https://i.cs.hku.hk/~taku/">Taku Komura</a>
                <sup>1</sup>
              </span>
            </li>

            <li>
              <span><a href="https://people.engr.tamu.edu/keyser/index.html">John Keyser</a>
                <sup>5</sup>
              </span>
            </li>

            <li>
              <span><a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a>
                <sup>5</sup>
              </span>
            </li>

        (*: equal contribution)


          </ul>
        </section>
        <section class="affiliations">
          <ul>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>1</sup>The University of Hong Kong,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>2</sup>The University of British Columbia,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>3</sup>City University of Hong Kong,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>4</sup>Zhejiang University,</li>
            <li style="font-family: 'Times New Roman', Arial;font-size: 18px; text-align: justify"><sup>5</sup>Texas A&M University</li>
          </ul>
        </section>
        <section class="links">
          <ul>
          
            <!-- <a><li>Video</li></a> -->
          </ul>
        </section>
        <a class="anchor" id="abstract-a"></a>
        <h2>Abstract</h2>
        <p class="abstract" style="font-family: 'Times New Roman', Arial; text-align: justify">
 
    Neural implicit fields, such as the signed distance field (SDF) of a shape, emerge as a powerful tool for many applications like representing a 3D shape and performing collision detection of these shapes. Typically, implicit fields are encoded by Multilayer Perceptrons (MLP), which brings advantages of compactness, smoothness, and topological flexibility. However, it often fails to capture high-frequency details due to the low-frequency essence of MLPs.
    To overcome this, sinusoidal positional encoding (PE) has become a popular and effective approach to enhancing the ability of the MLP to model high-frequency details in the target implicit field. However, a notable side effect of introducing PE to MLP is the noisy artifacts present in the learned implicit fields. The higher is the frequency components in PE, the more severe is this side effect. While increasing the sampling rate could in general mitigate these artifacts, in this paper we aim to provide an explanation for this adverse phenomenon through the lens of Fourier analysis and devise a tool for recommending the appropriate sampling rate necessary for learning an accurate neural implicit field without the undesirable side effects of using the PE. 
    </p>    
    <p class="abstract" style="font-family: 'Times New Roman', Arial; text-align: justify"></pclass>
    Specifically, we define the intrinsic frequency of a neural network (with or without PE) and propose a simple yet effective method for computing this intrinsic frequency of a given network based on Fourier analysis of the network with randomized weights. It is observed that a PE-equipped MLP has an intrinsic frequency much higher than the highest frequency component in the PE layer. Based on this observation, we recommend that the training sampling rate be determined by the intrinsic frequency of the PE-equipped MLP network.  We show empirically that this sampling rate is also sufficient in the sense that further increasing the sampling rate would not further noticeably decrease the fitting error. We validate our conclusions and methods in the setting of fitting SDF and show that the training strategy recommended by our study leads to superior performance than the existing methods. 
      
  </p>
  <img style="position:relative;top: 15px;" src='public/images/abstract.png' width="180">

      </section>


      <br />

    </main>
  </body>
</html>
